S3 -> object storage , get, pust, post interact using http methods, managed as individual objects no hierarchy
* object includes data itself, metadata and a global unique identifier
* data is unstructured, unlimited scalability and retention on massive amounts of unstructured data

EBS
provides persistent block storage volumes for use with EC2 instances in cloud
replicated within its AZ
persists independently of the life of instance
volumes dont need to be attached to instance
data is stored in blocks and volumes
mount amazon ec2 instance to a external harddrive/ssd
you can use block storage devices as boot volumes
similar to mounting data to a harddrive/ssd for containers
a ec2 instance can connect to multiple EBS volumes
a volume can only be connected to 1 EC2 instance
a ec2 instance can only connect to volume in same AZ
root EBS volumes are deleted on termination by default
*** uses EBS general purpose SSD by default
*** use EBS provisioned IOPS for highest performance especially for nosql & relational databases
*** use hard drives if you want to save money(big data) & cannot be used as boot volumes
*** EBS volume is attached over a network and is persistent

EFS(elastic file system)
manage data in a file hierarchy
a file system us mounted via network to a client computer where it becomes accessible for reading and writing data
protocols inlcude NFS

Simple object storage
connect client -> public internet -> amazon s3
        ec2 instance -> public internet -> amazon s3
        ec2 instance -> s3 gateway endpoint -> s3
can store any file in s3
high durability never lose the data
usecases:
   backup and storage
   application hosting -> maange web applications
   media hosting -> video, photo,music uploads and downloads
   software delivery -> host software apps others can download
   static website
* Files are stored in buckets
* buckets are root folders
* anywhere from 0 to 5TB
** s3 is a universal namepsace so bucket names must be unique globally
** create buckets in a region close to you
Object:
 key (name of object)
 value(data made up of seq if bytes)
 verId(used for versioning)
 metadata(data about data that is stored)
Pricing:
  storage
  requests
  storage management pricing
  data transfer pricing
  transfer acceleration

check amazon s3 storage classes
transfer acceleration -> speed up data uploads using cloudfront in reverse
requestor pays -> requester pay for requests and data transfer where as you pay for storage
tags
events -> trigger notifcations ton sns, sqs or lamda for certain events
static website hosting
bit torrent
*** cross region replication is possibel and also same region replication
  
*** Create a new role and attach it to a ec2 instance. After connecting through ssh you can read from s3.  

EBS snaphsots
volumes can be stored as snaphsots
stored on s3
snapshots are incremental so you can always store the latest volume
since EBS volumes are AZ specific, if you have a snapshot then you can use it to create a new EC2 instance and be able to use that volume since buckets exist across region.
Exercise: create Ec2 instance -> attach volume -> create snaphsot -> create AMI image -> create new EC2 instance in different AZ with custom AMI image -> launch

EFS
setup and scale file storage on amazon cloud
uses NFS
good for big data & analytics, content management, web serving, home directories 
data stored in multiple AZ's
pay for what u use
can scale up to petabytes
**** 1000s of Ec2 instances can connect to EFS
* accessed concurrently from all AZ's in a region
on prmeises can also connect to EFS using direct connect or AWS VPN.
*** EFS is a regional service
